{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/irteam/.pyenv/versions/3.6.4/envs/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "trn = pd.read_csv('data/train_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/irteam/.pyenv/versions/3.6.4/envs/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tst = pd.read_csv('data/test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove no posessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods = trn.columns[24:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna for target values\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_product = trn[prods].sum(axis=1) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = trn[~no_product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "    \n",
    "# merge train and test\n",
    "df = pd.concat([trn, tst], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fecha_dato',\n",
       " 'ncodpers',\n",
       " 'ind_empleado',\n",
       " 'pais_residencia',\n",
       " 'sexo',\n",
       " 'age',\n",
       " 'fecha_alta',\n",
       " 'ind_nuevo',\n",
       " 'antiguedad',\n",
       " 'indrel',\n",
       " 'ult_fec_cli_1t',\n",
       " 'indrel_1mes',\n",
       " 'tiprel_1mes',\n",
       " 'indresi',\n",
       " 'indext',\n",
       " 'conyuemp',\n",
       " 'canal_entrada',\n",
       " 'indfall',\n",
       " 'tipodom',\n",
       " 'cod_prov',\n",
       " 'nomprov',\n",
       " 'ind_actividad_cliente',\n",
       " 'renta',\n",
       " 'segmento']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:24].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', \n",
    "                'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel=-99)\n",
    "    \n",
    "features += categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].replace(' NA', -99, inplace=True)\n",
    "df['age'] = df['age'].astype(np.int8)\n",
    "\n",
    "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
    "\n",
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'] = df['renta'].astype(float).astype(np.int8)\n",
    "\n",
    "df['indrel_1mes'].replace('P', 5, inplace=True)\n",
    "df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
    "\n",
    "features += ['age','antiguedad','renta','ind_nuevo','indrel','indrel_1mes','ind_actividad_cliente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more feature engineering here\n",
    "\n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']\n",
    "\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha_dato\n",
      "['2015-01-28' '2015-02-28' '2015-03-28' '2015-04-28' '2015-05-28'\n",
      " '2015-06-28' '2015-07-28' '2015-08-28' '2015-09-28' '2015-10-28'\n",
      " '2015-11-28' '2015-12-28' '2016-01-28' '2016-02-28' '2016-03-28'\n",
      " '2016-04-28' '2016-05-28' '2016-06-28']\n",
      "ncodpers\n",
      "[1375586 1050611 1050612 ...,  660217  660231  660238]\n",
      "ind_empleado\n",
      "[  0 -99   1   2   3   4]\n",
      "pais_residencia\n",
      "[  0 -99   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16\n",
      "  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117]\n",
      "sexo\n",
      "[  0   1 -99]\n",
      "age\n",
      "[ 35  23  22  24  65  28  25  26  53  27  32  37  31  39  63  33  55  42\n",
      "  58  38  50  30  45  44  36  29  60  57  67  47 -99  34  48  46  54  84\n",
      "  15  12   8   6  83  40  77  69  52  59  43  10   9  49  41  51  78  16\n",
      "  11  73  62  66  17  68  82  95  96  56  61  79  14  19  13  86  64  20\n",
      "  72  89  71   7  70  74  21  18  75   4  80  81   5  76  92  93  85  91\n",
      "  87  90  94  99  98  88  97 100 101 106 103   3   2 102 104 111 107 109\n",
      " 105 112 115 110 116 108 113 114 117 -92 118 127]\n",
      "fecha_alta\n",
      "['2015-01-12' '2012-08-10' -99 ..., '2013-06-15' '2012-04-29' '2012-08-19']\n",
      "ind_nuevo\n",
      "[  0. -99.   1.]\n",
      "antiguedad\n",
      "[   6   35   34  -99   33   31   21   16   27    9   22   13   29    8   11\n",
      "   10   28   24    7   25   14   12   26   23    1   18    4    3   17   32\n",
      "   20   15   30   19   36   40   38   37   39    0    5   47   44   42   46\n",
      "   45   43   41   57   48   52   49   50   56   58   51   55   54   53   59\n",
      "   62   61   60   63    2 -117  -91  118  -92   94  -97 -113  105 -105  -94\n",
      " -119 -106 -128  122 -100  119  -96   79   95 -124  -95   98  127   72 -101\n",
      "  108  -93  102 -108  115 -110  107   81  -40 -121   92  121  -58 -122   93\n",
      " -116  110  120 -109   64   77   85   99   78  100  113 -102  -90  124 -115\n",
      "   66  117   86  -63   80 -112   87  126  -98  101  116  -21   88 -111  103\n",
      " -107  109 -125   97 -123   68   84  -24  125  -79  112   96   69  -85 -114\n",
      "  -89  104   76   82 -104   70 -118  -87   65 -127  -66  114  111  -80 -103\n",
      "   89 -120   83  123  -69  106  -25  -67  -39  -84  -57  -83  -82  -47  -76\n",
      "  -78  -88 -126  -31   67   73  -73   74  -50   71  -72  -64   91   90  -62\n",
      "  -74  -68  -43  -71  -61  -70  -49  -48   75  -81  -55  -53  -44  -41  -86\n",
      "  -28  -42  -54  -60  -75  -45  -65  -51  -56  -29  -38  -37  -30  -77  -32\n",
      "  -46  -14  -33  -19  -52  -23  -36  -34  -15  -59  -35  -27  -22  -16  -13\n",
      "  -26  -18  -10  -20  -12  -17  -11   -9   -8   -7   -6   -5   -4   -3   -2\n",
      "   -1]\n",
      "indrel\n",
      "[  1. -99.  99.]\n",
      "ult_fec_cli_1t\n",
      "[-99 '2015-07-02' '2015-07-23' '2015-07-06' '2015-07-30' '2015-07-20'\n",
      " '2015-07-08' '2015-07-22' '2015-07-17' '2015-07-09' '2015-07-03'\n",
      " '2015-07-29' '2015-07-13' '2015-07-21' '2015-07-27' '2015-07-14'\n",
      " '2015-07-01' '2015-07-24' '2015-07-15' '2015-07-16' '2015-07-28'\n",
      " '2015-07-07' '2015-07-10' '2015-08-25' '2015-08-19' '2015-08-12'\n",
      " '2015-08-27' '2015-08-07' '2015-08-20' '2015-08-14' '2015-08-17'\n",
      " '2015-08-06' '2015-08-10' '2015-08-18' '2015-08-24' '2015-08-26'\n",
      " '2015-08-05' '2015-08-11' '2015-08-13' '2015-08-28' '2015-09-01'\n",
      " '2015-09-08' '2015-09-11' '2015-09-22' '2015-09-17' '2015-09-21'\n",
      " '2015-09-29' '2015-09-28' '2015-09-15' '2015-09-14' '2015-09-07'\n",
      " '2015-09-10' '2015-09-04' '2015-09-18' '2015-09-23' '2015-09-02'\n",
      " '2015-09-25' '2015-09-16' '2015-09-03' '2015-10-13' '2015-10-28'\n",
      " '2015-10-09' '2015-10-15' '2015-10-05' '2015-10-21' '2015-10-16'\n",
      " '2015-10-01' '2015-10-07' '2015-10-26' '2015-10-27' '2015-10-02'\n",
      " '2015-10-29' '2015-10-14' '2015-10-08' '2015-10-19' '2015-10-20'\n",
      " '2015-10-23' '2015-11-25' '2015-11-13' '2015-11-11' '2015-11-17'\n",
      " '2015-11-24' '2015-11-02' '2015-11-16' '2015-11-18' '2015-11-12'\n",
      " '2015-11-03' '2015-11-27' '2015-11-04' '2015-11-23' '2015-11-19'\n",
      " '2015-11-10' '2015-11-26' '2015-11-20' '2015-11-09' '2015-12-21'\n",
      " '2015-12-29' '2015-12-16' '2015-12-24' '2015-12-07' '2015-12-28'\n",
      " '2015-12-23' '2015-12-17' '2015-12-14' '2015-12-15' '2015-12-01'\n",
      " '2015-12-10' '2015-12-30' '2015-12-11' '2015-12-18' '2015-12-03'\n",
      " '2015-12-04' '2015-12-02' '2015-12-22' '2015-12-09' '2016-01-20'\n",
      " '2016-01-15' '2016-01-25' '2016-01-08' '2016-01-05' '2016-01-13'\n",
      " '2016-01-18' '2016-01-28' '2016-01-26' '2016-01-21' '2016-01-12'\n",
      " '2016-01-22' '2016-01-27' '2016-01-19' '2016-01-07' '2016-01-14'\n",
      " '2016-02-23' '2016-02-03' '2016-02-15' '2016-02-16' '2016-02-26'\n",
      " '2016-02-17' '2016-02-22' '2016-02-11' '2016-02-04' '2016-02-12'\n",
      " '2016-02-02' '2016-02-24' '2016-02-05' '2016-02-10' '2016-02-19'\n",
      " '2016-02-08' '2016-02-09' '2016-02-25' '2016-02-18' '2016-02-01'\n",
      " '2016-03-22' '2016-03-14' '2016-03-18' '2016-03-24' '2016-03-09'\n",
      " '2016-03-04' '2016-03-29' '2016-03-10' '2016-03-21' '2016-03-28'\n",
      " '2016-03-30' '2016-03-11' '2016-03-07' '2016-03-16' '2016-03-01'\n",
      " '2016-03-17' '2016-03-15' '2016-03-03' '2016-03-08' '2016-03-23'\n",
      " '2016-04-05' '2016-04-18' '2016-04-06' '2016-04-01' '2016-04-21'\n",
      " '2016-04-12' '2016-04-04' '2016-04-26' '2016-04-22' '2016-04-15'\n",
      " '2016-04-08' '2016-04-20' '2016-04-19' '2016-04-14' '2016-04-28'\n",
      " '2016-04-11' '2016-04-25' '2016-04-13' '2016-05-24' '2016-05-20'\n",
      " '2016-05-16' '2016-05-06' '2016-05-18' '2016-05-02' '2016-05-26'\n",
      " '2016-05-25' '2016-05-11' '2016-05-05' '2016-05-12' '2016-05-23'\n",
      " '2016-05-30' '2016-05-03' '2016-05-10' '2016-05-27' '2016-05-19'\n",
      " '2016-05-04' '2016-05-13' '2016-06-03' '2016-06-24' '2016-06-22'\n",
      " '2016-06-02' '2016-06-14' '2016-06-07' '2016-06-28' '2016-06-27'\n",
      " '2016-06-20' '2016-06-10' '2016-06-01' '2016-06-08' '2016-06-17'\n",
      " '2016-06-06' '2016-06-23' '2016-06-21' '2016-06-29' '2016-06-16'\n",
      " '2016-06-09' '2016-06-15' '2016-06-13']\n",
      "indrel_1mes\n",
      "[  1 -99   3   2   5   4]\n",
      "tiprel_1mes\n",
      "[  0   1 -99   2   3   4]\n",
      "indresi\n",
      "[  0 -99   1]\n",
      "indext\n",
      "[  0   1 -99]\n",
      "conyuemp\n",
      "[-99   0   1]\n",
      "canal_entrada\n",
      "[  0   1   2   3   4   5 -99   6   7   8   9  10  11  12  13  14  15  16\n",
      "  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161]\n",
      "indfall\n",
      "[  0 -99   1]\n",
      "tipodom\n",
      "[  0 -99]\n",
      "cod_prov\n",
      "[ 29.  13.  50.  45.  24.  20.  10.  17.  49.   8.  37.   9.  22.  31.   5.\n",
      "  40.  27.  25.  28.   3.  42.  41.  39.   7.  47.  36.  46.  44.  15.  32.\n",
      "  23.  16.  48.  12.  26.   2.   6.  30.  11. -99.   4.  19.  34.  35.  14.\n",
      "  21.  18.  33.  38.  52.  43.   1.  51.]\n",
      "nomprov\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38 -99  39  40  41  42  43  44  45  46  47  48  49  50  51]\n",
      "ind_actividad_cliente\n",
      "[  1.   0. -99.]\n",
      "renta\n",
      "[ -78  -36   67  -33  -99  -52  -90  -92   42  127 -126  -91  -34   72  -40\n",
      "  108  -62 -123  104   79   69   40   28   82 -110   23  121    8 -114 -122\n",
      "   31   63    7  -45   60  -80   93  -66   46  112   88  -37  -69  102   34\n",
      "  -30  -59   33  -57  -18  107   70  -88  -14  126   35  -89  -28   61  114\n",
      "    9   77    2   26   49  -44   59   71   27  -54  -96  -83  -84   -1  -93\n",
      " -111  -73   -5   57  -79   58   95  -97   20  110  125  -63   15  -56   65\n",
      "   91   44   68   54    0   37  100  -20  -58  -74 -115  -21  -23  -12   87\n",
      "   11 -118  -22  113   98   13   25 -108   14  120  -27  105 -100 -117   30\n",
      "  -15  -31   36  -29  -47   -9  122  -70  -41   75   53  -32   -7   -3   73\n",
      "   94  119 -121   38   52  -16 -103  -72  -35   84   64   81  118 -116  -61\n",
      " -102   -8   29  -46   97  -71  -85  -95  -26  -55  109  -49   16 -127   55\n",
      "   12 -112   19   74    4  -77   -4  -94   -2  115  -11  123  -25   51   80\n",
      "    5 -119 -105  106   45  -81  116   78  -51 -125   76  -17   22   -6   56\n",
      "   41   90  -86  103   92  -60  124 -107  -42  -43  -68   99  -10  -82   96\n",
      "  117 -101   62   17   83   18  -19  -64   24    1 -113   66  101  -87  -75\n",
      " -124  -53  -67 -128 -106  -65   32  111   43 -104 -120   85  -38   21  -50\n",
      "    6   47   10   86 -109   89   50  -76  -98    3   39  -39  -48  -13  -24\n",
      "   48]\n",
      "segmento\n",
      "[  0   1 -99   2]\n",
      "ind_ahor_fin_ult1\n",
      "[0 1]\n",
      "ind_aval_fin_ult1\n",
      "[0 1]\n",
      "ind_cco_fin_ult1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "ind_cder_fin_ult1\n",
      "[0 1]\n",
      "ind_cno_fin_ult1\n",
      "[0 1]\n",
      "ind_ctju_fin_ult1\n",
      "[0 1]\n",
      "ind_ctma_fin_ult1\n",
      "[0 1]\n",
      "ind_ctop_fin_ult1\n",
      "[0 1]\n",
      "ind_ctpp_fin_ult1\n",
      "[0 1]\n",
      "ind_deco_fin_ult1\n",
      "[0 1]\n",
      "ind_deme_fin_ult1\n",
      "[0 1]\n",
      "ind_dela_fin_ult1\n",
      "[0 1]\n",
      "ind_ecue_fin_ult1\n",
      "[0 1]\n",
      "ind_fond_fin_ult1\n",
      "[0 1]\n",
      "ind_hip_fin_ult1\n",
      "[0 1]\n",
      "ind_plan_fin_ult1\n",
      "[0 1]\n",
      "ind_pres_fin_ult1\n",
      "[0 1]\n",
      "ind_reca_fin_ult1\n",
      "[0 1]\n",
      "ind_tjcr_fin_ult1\n",
      "[0 1]\n",
      "ind_valo_fin_ult1\n",
      "[0 1]\n",
      "ind_viv_fin_ult1\n",
      "[0 1]\n",
      "ind_nomina_ult1\n",
      "[0 1]\n",
      "ind_nom_pens_ult1\n",
      "[0 1]\n",
      "ind_recibo_ult1\n",
      "[0 1]\n",
      "fecha_alta_month\n",
      "[ 1  8  0 10  7 12  9  3  4  2 11  5  6]\n",
      "fecha_alta_year\n",
      "[2015 2012    0 2014 2013 2005 2002 2004 2003 2006 2007 2011 2009 2010 2001\n",
      " 1999 2008 1997 1998 2000 1996 1995 2016]\n",
      "ult_fec_cli_1t_month\n",
      "[ 0  7  8  9 10 11 12  1  2  3  4  5  6]\n",
      "ult_fec_cli_1t_year\n",
      "[   0 2015 2016]\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] # \"2016-05-28\"\n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lag = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lag['int_date'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12020685, 53), (12020685, 53), (12020685, 104))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_lag.shape, df_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [feature + '_prev' for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [prod + '_prev' for prod in prods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = df_trn[~df_trn['fecha_dato'].isin(['2016-05-28', '2016-06-28'])]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-05-28']\n",
    "submit = df_trn[df_trn['fecha_dato'] == '2016-06-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10394531, 104), (696539, 104), (929615, 104))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape, tst.shape, submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = pd.concat(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.hstack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY['y'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.rand(len(XY)) < 0.8\n",
    "XY_trn = XY[mask]\n",
    "XY_vld = XY[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "ncodpers_submit = submit.as_matrix(columns=['ncodpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/irteam/.pyenv/versions/3.6.4/envs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    tst[padd] = tst[prod] - tst[prev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tst = tst.as_matrix(columns=[prod + '_add' for prod in prods])\n",
    "add_tst_list = [list() for i in range(len(ncodpers_tst))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tst = 0\n",
    "for ncodper in range(len(ncodpers_tst)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_tst[ncodper, prod] > 0:\n",
    "            add_tst_list[ncodper].append(prod)\n",
    "            count_tst += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=7, default=0.0):\n",
    "    # MAP@7 이므로, 최대 7개만 사용한다\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # 점수를 부여하는 조건은 다음과 같다 :\n",
    "        # 예측값이 정답에 있고 (‘p in actual’)\n",
    "        # 예측값이 중복이 아니면 (‘p not in predicted[:i]’) \n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    # 정답값이 공백일 경우, 무조건 1.0점을 반환한다\n",
    "    if not actual:\n",
    "        return default\n",
    "\n",
    "    # 정답의 개수(len(actual))로 average precision을 구한다\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=7, default=0.0):\n",
    "    # list of list인 정답값(actual)과 예측값(predicted)에서 고객별 Average Precision을 구하고, np.mean()을 통해 평균을 계산한다\n",
    "    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042663799155539028"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(add_tst_list, add_tst_list, 7, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param = {\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 8,\n",
    "    'nthread': 24,\n",
    "    'num_class': len(prods),\n",
    "    'objective': 'multi:softprob',\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'eta': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'colsample_bylevel': 0.9,\n",
    "    'seed': 2018,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = XY_trn.as_matrix(columns=features)\n",
    "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
    "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vld = XY_vld.as_matrix(columns=features)\n",
    "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.79508\teval-mlogloss:2.79615\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:2.56889\teval-mlogloss:2.57081\n",
      "[2]\ttrain-mlogloss:2.39626\teval-mlogloss:2.39868\n",
      "[3]\ttrain-mlogloss:2.2642\teval-mlogloss:2.26725\n",
      "[4]\ttrain-mlogloss:2.16456\teval-mlogloss:2.16852\n",
      "[5]\ttrain-mlogloss:2.07093\teval-mlogloss:2.07553\n",
      "[6]\ttrain-mlogloss:1.99467\teval-mlogloss:1.99991\n",
      "[7]\ttrain-mlogloss:1.92661\teval-mlogloss:1.93244\n",
      "[8]\ttrain-mlogloss:1.86707\teval-mlogloss:1.87344\n",
      "[9]\ttrain-mlogloss:1.81729\teval-mlogloss:1.82424\n",
      "[10]\ttrain-mlogloss:1.77208\teval-mlogloss:1.77969\n",
      "[11]\ttrain-mlogloss:1.72986\teval-mlogloss:1.73812\n",
      "[12]\ttrain-mlogloss:1.69358\teval-mlogloss:1.70251\n",
      "[13]\ttrain-mlogloss:1.65966\teval-mlogloss:1.66912\n",
      "[14]\ttrain-mlogloss:1.63031\teval-mlogloss:1.64045\n",
      "[15]\ttrain-mlogloss:1.60192\teval-mlogloss:1.61256\n",
      "[16]\ttrain-mlogloss:1.57589\teval-mlogloss:1.58708\n",
      "[17]\ttrain-mlogloss:1.5518\teval-mlogloss:1.56349\n",
      "[18]\ttrain-mlogloss:1.53026\teval-mlogloss:1.5425\n",
      "[19]\ttrain-mlogloss:1.5102\teval-mlogloss:1.523\n",
      "[20]\ttrain-mlogloss:1.49269\teval-mlogloss:1.50611\n",
      "[21]\ttrain-mlogloss:1.47662\teval-mlogloss:1.4906\n",
      "[22]\ttrain-mlogloss:1.46148\teval-mlogloss:1.47603\n",
      "[23]\ttrain-mlogloss:1.44667\teval-mlogloss:1.46169\n",
      "[24]\ttrain-mlogloss:1.43366\teval-mlogloss:1.44923\n",
      "[25]\ttrain-mlogloss:1.4209\teval-mlogloss:1.43694\n",
      "[26]\ttrain-mlogloss:1.40953\teval-mlogloss:1.42613\n",
      "[27]\ttrain-mlogloss:1.39894\teval-mlogloss:1.41612\n",
      "[28]\ttrain-mlogloss:1.38915\teval-mlogloss:1.40681\n",
      "[29]\ttrain-mlogloss:1.37991\teval-mlogloss:1.3981\n",
      "[30]\ttrain-mlogloss:1.37146\teval-mlogloss:1.39014\n",
      "[31]\ttrain-mlogloss:1.36343\teval-mlogloss:1.38265\n",
      "[32]\ttrain-mlogloss:1.35553\teval-mlogloss:1.37529\n",
      "[33]\ttrain-mlogloss:1.34808\teval-mlogloss:1.36837\n",
      "[34]\ttrain-mlogloss:1.34154\teval-mlogloss:1.3623\n",
      "[35]\ttrain-mlogloss:1.33535\teval-mlogloss:1.35668\n",
      "[36]\ttrain-mlogloss:1.32913\teval-mlogloss:1.35097\n",
      "[37]\ttrain-mlogloss:1.32333\teval-mlogloss:1.34566\n",
      "[38]\ttrain-mlogloss:1.31782\teval-mlogloss:1.3407\n",
      "[39]\ttrain-mlogloss:1.31274\teval-mlogloss:1.33612\n",
      "[40]\ttrain-mlogloss:1.30779\teval-mlogloss:1.33162\n",
      "[41]\ttrain-mlogloss:1.3032\teval-mlogloss:1.32749\n",
      "[42]\ttrain-mlogloss:1.29881\teval-mlogloss:1.32364\n",
      "[43]\ttrain-mlogloss:1.29458\teval-mlogloss:1.31992\n",
      "[44]\ttrain-mlogloss:1.29065\teval-mlogloss:1.31657\n",
      "[45]\ttrain-mlogloss:1.28699\teval-mlogloss:1.31342\n",
      "[46]\ttrain-mlogloss:1.28343\teval-mlogloss:1.31037\n",
      "[47]\ttrain-mlogloss:1.27997\teval-mlogloss:1.30735\n",
      "[48]\ttrain-mlogloss:1.27673\teval-mlogloss:1.30461\n",
      "[49]\ttrain-mlogloss:1.27361\teval-mlogloss:1.30196\n",
      "[50]\ttrain-mlogloss:1.27063\teval-mlogloss:1.29948\n",
      "[51]\ttrain-mlogloss:1.26794\teval-mlogloss:1.29719\n",
      "[52]\ttrain-mlogloss:1.26533\teval-mlogloss:1.29502\n",
      "[53]\ttrain-mlogloss:1.26278\teval-mlogloss:1.29297\n",
      "[54]\ttrain-mlogloss:1.26036\teval-mlogloss:1.291\n",
      "[55]\ttrain-mlogloss:1.258\teval-mlogloss:1.2891\n",
      "[56]\ttrain-mlogloss:1.25579\teval-mlogloss:1.28734\n",
      "[57]\ttrain-mlogloss:1.25375\teval-mlogloss:1.28573\n",
      "[58]\ttrain-mlogloss:1.25181\teval-mlogloss:1.28423\n",
      "[59]\ttrain-mlogloss:1.24988\teval-mlogloss:1.28268\n",
      "[60]\ttrain-mlogloss:1.24803\teval-mlogloss:1.28131\n",
      "[61]\ttrain-mlogloss:1.24611\teval-mlogloss:1.27981\n",
      "[62]\ttrain-mlogloss:1.24446\teval-mlogloss:1.27855\n",
      "[63]\ttrain-mlogloss:1.24282\teval-mlogloss:1.2773\n",
      "[64]\ttrain-mlogloss:1.24141\teval-mlogloss:1.27626\n",
      "[65]\ttrain-mlogloss:1.23994\teval-mlogloss:1.27517\n",
      "[66]\ttrain-mlogloss:1.23844\teval-mlogloss:1.2741\n",
      "[67]\ttrain-mlogloss:1.23697\teval-mlogloss:1.27302\n",
      "[68]\ttrain-mlogloss:1.23547\teval-mlogloss:1.27198\n",
      "[69]\ttrain-mlogloss:1.23407\teval-mlogloss:1.27098\n",
      "[70]\ttrain-mlogloss:1.2327\teval-mlogloss:1.27006\n",
      "[71]\ttrain-mlogloss:1.23156\teval-mlogloss:1.26923\n",
      "[72]\ttrain-mlogloss:1.23031\teval-mlogloss:1.26837\n",
      "[73]\ttrain-mlogloss:1.22915\teval-mlogloss:1.26768\n",
      "[74]\ttrain-mlogloss:1.22798\teval-mlogloss:1.26689\n",
      "[75]\ttrain-mlogloss:1.22686\teval-mlogloss:1.26617\n",
      "[76]\ttrain-mlogloss:1.22586\teval-mlogloss:1.26552\n",
      "[77]\ttrain-mlogloss:1.22486\teval-mlogloss:1.26485\n",
      "[78]\ttrain-mlogloss:1.22388\teval-mlogloss:1.26421\n",
      "[79]\ttrain-mlogloss:1.22298\teval-mlogloss:1.26364\n",
      "[80]\ttrain-mlogloss:1.22199\teval-mlogloss:1.26306\n",
      "[81]\ttrain-mlogloss:1.22105\teval-mlogloss:1.26252\n",
      "[82]\ttrain-mlogloss:1.22022\teval-mlogloss:1.26205\n",
      "[83]\ttrain-mlogloss:1.21935\teval-mlogloss:1.26153\n",
      "[84]\ttrain-mlogloss:1.2184\teval-mlogloss:1.26104\n",
      "[85]\ttrain-mlogloss:1.21762\teval-mlogloss:1.26058\n",
      "[86]\ttrain-mlogloss:1.21674\teval-mlogloss:1.26012\n",
      "[87]\ttrain-mlogloss:1.21592\teval-mlogloss:1.25966\n",
      "[88]\ttrain-mlogloss:1.21525\teval-mlogloss:1.25933\n",
      "[89]\ttrain-mlogloss:1.21449\teval-mlogloss:1.25896\n",
      "[90]\ttrain-mlogloss:1.21374\teval-mlogloss:1.2586\n",
      "[91]\ttrain-mlogloss:1.21304\teval-mlogloss:1.25824\n",
      "[92]\ttrain-mlogloss:1.21237\teval-mlogloss:1.25791\n",
      "[93]\ttrain-mlogloss:1.21178\teval-mlogloss:1.25759\n",
      "[94]\ttrain-mlogloss:1.2112\teval-mlogloss:1.25731\n",
      "[95]\ttrain-mlogloss:1.21054\teval-mlogloss:1.25703\n",
      "[96]\ttrain-mlogloss:1.20988\teval-mlogloss:1.25674\n",
      "[97]\ttrain-mlogloss:1.20936\teval-mlogloss:1.25647\n",
      "[98]\ttrain-mlogloss:1.20865\teval-mlogloss:1.25609\n",
      "[99]\ttrain-mlogloss:1.20816\teval-mlogloss:1.25584\n",
      "[100]\ttrain-mlogloss:1.2075\teval-mlogloss:1.25557\n",
      "[101]\ttrain-mlogloss:1.20683\teval-mlogloss:1.25528\n",
      "[102]\ttrain-mlogloss:1.20616\teval-mlogloss:1.25505\n",
      "[103]\ttrain-mlogloss:1.20557\teval-mlogloss:1.25478\n",
      "[104]\ttrain-mlogloss:1.20488\teval-mlogloss:1.2545\n",
      "[105]\ttrain-mlogloss:1.20433\teval-mlogloss:1.25426\n",
      "[106]\ttrain-mlogloss:1.20374\teval-mlogloss:1.25402\n",
      "[107]\ttrain-mlogloss:1.203\teval-mlogloss:1.25376\n",
      "[108]\ttrain-mlogloss:1.20239\teval-mlogloss:1.25349\n",
      "[109]\ttrain-mlogloss:1.202\teval-mlogloss:1.25337\n",
      "[110]\ttrain-mlogloss:1.20147\teval-mlogloss:1.25315\n",
      "[111]\ttrain-mlogloss:1.20089\teval-mlogloss:1.25298\n",
      "[112]\ttrain-mlogloss:1.20037\teval-mlogloss:1.25282\n",
      "[113]\ttrain-mlogloss:1.19983\teval-mlogloss:1.25262\n",
      "[114]\ttrain-mlogloss:1.19918\teval-mlogloss:1.25238\n",
      "[115]\ttrain-mlogloss:1.19873\teval-mlogloss:1.25227\n",
      "[116]\ttrain-mlogloss:1.19828\teval-mlogloss:1.25209\n",
      "[117]\ttrain-mlogloss:1.19781\teval-mlogloss:1.25193\n",
      "[118]\ttrain-mlogloss:1.19724\teval-mlogloss:1.25172\n",
      "[119]\ttrain-mlogloss:1.19687\teval-mlogloss:1.25163\n",
      "[120]\ttrain-mlogloss:1.19633\teval-mlogloss:1.25147\n",
      "[121]\ttrain-mlogloss:1.19588\teval-mlogloss:1.25135\n",
      "[122]\ttrain-mlogloss:1.19535\teval-mlogloss:1.25119\n",
      "[123]\ttrain-mlogloss:1.19488\teval-mlogloss:1.25108\n",
      "[124]\ttrain-mlogloss:1.19442\teval-mlogloss:1.25098\n",
      "[125]\ttrain-mlogloss:1.19398\teval-mlogloss:1.25089\n",
      "[126]\ttrain-mlogloss:1.1935\teval-mlogloss:1.25077\n",
      "[127]\ttrain-mlogloss:1.19308\teval-mlogloss:1.25069\n",
      "[128]\ttrain-mlogloss:1.19264\teval-mlogloss:1.25055\n",
      "[129]\ttrain-mlogloss:1.19224\teval-mlogloss:1.25045\n",
      "[130]\ttrain-mlogloss:1.19169\teval-mlogloss:1.25035\n",
      "[131]\ttrain-mlogloss:1.19113\teval-mlogloss:1.25021\n",
      "[132]\ttrain-mlogloss:1.19066\teval-mlogloss:1.25013\n",
      "[133]\ttrain-mlogloss:1.19022\teval-mlogloss:1.25004\n",
      "[134]\ttrain-mlogloss:1.18986\teval-mlogloss:1.24997\n",
      "[135]\ttrain-mlogloss:1.1894\teval-mlogloss:1.2499\n",
      "[136]\ttrain-mlogloss:1.18894\teval-mlogloss:1.24979\n",
      "[137]\ttrain-mlogloss:1.18841\teval-mlogloss:1.24969\n",
      "[138]\ttrain-mlogloss:1.18804\teval-mlogloss:1.24962\n",
      "[139]\ttrain-mlogloss:1.18761\teval-mlogloss:1.24958\n",
      "[140]\ttrain-mlogloss:1.18708\teval-mlogloss:1.24955\n",
      "[141]\ttrain-mlogloss:1.18661\teval-mlogloss:1.24948\n",
      "[142]\ttrain-mlogloss:1.18628\teval-mlogloss:1.24941\n",
      "[143]\ttrain-mlogloss:1.18582\teval-mlogloss:1.24934\n",
      "[144]\ttrain-mlogloss:1.18547\teval-mlogloss:1.24927\n",
      "[145]\ttrain-mlogloss:1.18499\teval-mlogloss:1.2492\n",
      "[146]\ttrain-mlogloss:1.18437\teval-mlogloss:1.24914\n",
      "[147]\ttrain-mlogloss:1.1839\teval-mlogloss:1.24907\n",
      "[148]\ttrain-mlogloss:1.18344\teval-mlogloss:1.24904\n",
      "[149]\ttrain-mlogloss:1.18298\teval-mlogloss:1.24894\n",
      "[150]\ttrain-mlogloss:1.18253\teval-mlogloss:1.24887\n",
      "[151]\ttrain-mlogloss:1.18197\teval-mlogloss:1.24872\n",
      "[152]\ttrain-mlogloss:1.18139\teval-mlogloss:1.24859\n",
      "[153]\ttrain-mlogloss:1.18097\teval-mlogloss:1.2485\n",
      "[154]\ttrain-mlogloss:1.18053\teval-mlogloss:1.24843\n",
      "[155]\ttrain-mlogloss:1.17993\teval-mlogloss:1.24832\n",
      "[156]\ttrain-mlogloss:1.17947\teval-mlogloss:1.24829\n",
      "[157]\ttrain-mlogloss:1.17905\teval-mlogloss:1.24823\n",
      "[158]\ttrain-mlogloss:1.17865\teval-mlogloss:1.24819\n",
      "[159]\ttrain-mlogloss:1.1781\teval-mlogloss:1.24813\n",
      "[160]\ttrain-mlogloss:1.17773\teval-mlogloss:1.24809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttrain-mlogloss:1.17721\teval-mlogloss:1.24802\n",
      "[162]\ttrain-mlogloss:1.17663\teval-mlogloss:1.24793\n",
      "[163]\ttrain-mlogloss:1.17623\teval-mlogloss:1.24792\n",
      "[164]\ttrain-mlogloss:1.17574\teval-mlogloss:1.24784\n",
      "[165]\ttrain-mlogloss:1.17527\teval-mlogloss:1.24776\n",
      "[166]\ttrain-mlogloss:1.17477\teval-mlogloss:1.24769\n",
      "[167]\ttrain-mlogloss:1.17419\teval-mlogloss:1.24756\n",
      "[168]\ttrain-mlogloss:1.17371\teval-mlogloss:1.24752\n",
      "[169]\ttrain-mlogloss:1.17321\teval-mlogloss:1.24742\n",
      "[170]\ttrain-mlogloss:1.1728\teval-mlogloss:1.2474\n",
      "[171]\ttrain-mlogloss:1.17215\teval-mlogloss:1.24726\n",
      "[172]\ttrain-mlogloss:1.17168\teval-mlogloss:1.24723\n",
      "[173]\ttrain-mlogloss:1.17114\teval-mlogloss:1.24715\n",
      "[174]\ttrain-mlogloss:1.17066\teval-mlogloss:1.2471\n",
      "[175]\ttrain-mlogloss:1.17005\teval-mlogloss:1.24697\n",
      "[176]\ttrain-mlogloss:1.16964\teval-mlogloss:1.24694\n",
      "[177]\ttrain-mlogloss:1.16918\teval-mlogloss:1.24692\n",
      "[178]\ttrain-mlogloss:1.16869\teval-mlogloss:1.24687\n",
      "[179]\ttrain-mlogloss:1.16828\teval-mlogloss:1.24681\n",
      "[180]\ttrain-mlogloss:1.16784\teval-mlogloss:1.24678\n",
      "[181]\ttrain-mlogloss:1.16733\teval-mlogloss:1.24672\n",
      "[182]\ttrain-mlogloss:1.16685\teval-mlogloss:1.24666\n",
      "[183]\ttrain-mlogloss:1.16633\teval-mlogloss:1.24662\n",
      "[184]\ttrain-mlogloss:1.16588\teval-mlogloss:1.24658\n",
      "[185]\ttrain-mlogloss:1.16548\teval-mlogloss:1.24656\n",
      "[186]\ttrain-mlogloss:1.16503\teval-mlogloss:1.24655\n",
      "[187]\ttrain-mlogloss:1.16452\teval-mlogloss:1.2465\n",
      "[188]\ttrain-mlogloss:1.16404\teval-mlogloss:1.24646\n",
      "[189]\ttrain-mlogloss:1.16352\teval-mlogloss:1.24639\n",
      "[190]\ttrain-mlogloss:1.16304\teval-mlogloss:1.24633\n",
      "[191]\ttrain-mlogloss:1.16265\teval-mlogloss:1.24632\n",
      "[192]\ttrain-mlogloss:1.16203\teval-mlogloss:1.24621\n",
      "[193]\ttrain-mlogloss:1.16161\teval-mlogloss:1.24617\n",
      "[194]\ttrain-mlogloss:1.16102\teval-mlogloss:1.24608\n",
      "[195]\ttrain-mlogloss:1.16054\teval-mlogloss:1.246\n",
      "[196]\ttrain-mlogloss:1.16004\teval-mlogloss:1.24598\n",
      "[197]\ttrain-mlogloss:1.15948\teval-mlogloss:1.24591\n",
      "[198]\ttrain-mlogloss:1.15892\teval-mlogloss:1.24585\n",
      "[199]\ttrain-mlogloss:1.15847\teval-mlogloss:1.24581\n",
      "[200]\ttrain-mlogloss:1.15793\teval-mlogloss:1.24578\n",
      "[201]\ttrain-mlogloss:1.15745\teval-mlogloss:1.24571\n",
      "[202]\ttrain-mlogloss:1.15702\teval-mlogloss:1.24564\n",
      "[203]\ttrain-mlogloss:1.15634\teval-mlogloss:1.24549\n",
      "[204]\ttrain-mlogloss:1.15587\teval-mlogloss:1.24548\n",
      "[205]\ttrain-mlogloss:1.15533\teval-mlogloss:1.24542\n",
      "[206]\ttrain-mlogloss:1.15488\teval-mlogloss:1.24535\n",
      "[207]\ttrain-mlogloss:1.15449\teval-mlogloss:1.24532\n",
      "[208]\ttrain-mlogloss:1.1541\teval-mlogloss:1.24531\n",
      "[209]\ttrain-mlogloss:1.15369\teval-mlogloss:1.24529\n",
      "[210]\ttrain-mlogloss:1.15328\teval-mlogloss:1.24528\n",
      "[211]\ttrain-mlogloss:1.1529\teval-mlogloss:1.24527\n",
      "[212]\ttrain-mlogloss:1.15233\teval-mlogloss:1.24522\n",
      "[213]\ttrain-mlogloss:1.15189\teval-mlogloss:1.2452\n",
      "[214]\ttrain-mlogloss:1.15135\teval-mlogloss:1.24514\n",
      "[215]\ttrain-mlogloss:1.15091\teval-mlogloss:1.24509\n",
      "[216]\ttrain-mlogloss:1.15053\teval-mlogloss:1.24509\n",
      "[217]\ttrain-mlogloss:1.15004\teval-mlogloss:1.24504\n",
      "[218]\ttrain-mlogloss:1.14953\teval-mlogloss:1.24502\n",
      "[219]\ttrain-mlogloss:1.14909\teval-mlogloss:1.24502\n",
      "[220]\ttrain-mlogloss:1.14865\teval-mlogloss:1.24498\n",
      "[221]\ttrain-mlogloss:1.14814\teval-mlogloss:1.2449\n",
      "[222]\ttrain-mlogloss:1.14776\teval-mlogloss:1.24489\n",
      "[223]\ttrain-mlogloss:1.14726\teval-mlogloss:1.24487\n",
      "[224]\ttrain-mlogloss:1.14673\teval-mlogloss:1.24489\n",
      "[225]\ttrain-mlogloss:1.14625\teval-mlogloss:1.2448\n",
      "[226]\ttrain-mlogloss:1.1459\teval-mlogloss:1.24482\n",
      "[227]\ttrain-mlogloss:1.14549\teval-mlogloss:1.24482\n",
      "[228]\ttrain-mlogloss:1.14509\teval-mlogloss:1.24483\n",
      "[229]\ttrain-mlogloss:1.14463\teval-mlogloss:1.24477\n",
      "[230]\ttrain-mlogloss:1.1442\teval-mlogloss:1.24472\n",
      "[231]\ttrain-mlogloss:1.14371\teval-mlogloss:1.24463\n",
      "[232]\ttrain-mlogloss:1.1433\teval-mlogloss:1.24459\n",
      "[233]\ttrain-mlogloss:1.14293\teval-mlogloss:1.24457\n",
      "[234]\ttrain-mlogloss:1.14245\teval-mlogloss:1.24456\n",
      "[235]\ttrain-mlogloss:1.14209\teval-mlogloss:1.24456\n",
      "[236]\ttrain-mlogloss:1.14167\teval-mlogloss:1.24455\n",
      "[237]\ttrain-mlogloss:1.14132\teval-mlogloss:1.24453\n",
      "[238]\ttrain-mlogloss:1.14086\teval-mlogloss:1.2445\n",
      "[239]\ttrain-mlogloss:1.14055\teval-mlogloss:1.2445\n",
      "[240]\ttrain-mlogloss:1.14015\teval-mlogloss:1.24445\n",
      "[241]\ttrain-mlogloss:1.13969\teval-mlogloss:1.24439\n",
      "[242]\ttrain-mlogloss:1.13934\teval-mlogloss:1.24441\n",
      "[243]\ttrain-mlogloss:1.13887\teval-mlogloss:1.24436\n",
      "[244]\ttrain-mlogloss:1.1385\teval-mlogloss:1.24435\n",
      "[245]\ttrain-mlogloss:1.13811\teval-mlogloss:1.24436\n",
      "[246]\ttrain-mlogloss:1.13767\teval-mlogloss:1.24432\n",
      "[247]\ttrain-mlogloss:1.13718\teval-mlogloss:1.24429\n",
      "[248]\ttrain-mlogloss:1.1367\teval-mlogloss:1.24425\n",
      "[249]\ttrain-mlogloss:1.13626\teval-mlogloss:1.24423\n",
      "[250]\ttrain-mlogloss:1.13585\teval-mlogloss:1.24419\n",
      "[251]\ttrain-mlogloss:1.13545\teval-mlogloss:1.2442\n",
      "[252]\ttrain-mlogloss:1.13494\teval-mlogloss:1.24413\n",
      "[253]\ttrain-mlogloss:1.1345\teval-mlogloss:1.2441\n",
      "[254]\ttrain-mlogloss:1.13416\teval-mlogloss:1.24408\n",
      "[255]\ttrain-mlogloss:1.13377\teval-mlogloss:1.24407\n",
      "[256]\ttrain-mlogloss:1.13346\teval-mlogloss:1.24407\n",
      "[257]\ttrain-mlogloss:1.13315\teval-mlogloss:1.24411\n",
      "[258]\ttrain-mlogloss:1.13278\teval-mlogloss:1.24415\n",
      "[259]\ttrain-mlogloss:1.13237\teval-mlogloss:1.24412\n",
      "[260]\ttrain-mlogloss:1.13197\teval-mlogloss:1.2441\n",
      "[261]\ttrain-mlogloss:1.13157\teval-mlogloss:1.24408\n",
      "[262]\ttrain-mlogloss:1.1311\teval-mlogloss:1.24401\n",
      "[263]\ttrain-mlogloss:1.13067\teval-mlogloss:1.24395\n",
      "[264]\ttrain-mlogloss:1.1303\teval-mlogloss:1.24395\n",
      "[265]\ttrain-mlogloss:1.12984\teval-mlogloss:1.24393\n",
      "[266]\ttrain-mlogloss:1.12937\teval-mlogloss:1.24388\n",
      "[267]\ttrain-mlogloss:1.12896\teval-mlogloss:1.2439\n",
      "[268]\ttrain-mlogloss:1.12864\teval-mlogloss:1.24393\n",
      "[269]\ttrain-mlogloss:1.12828\teval-mlogloss:1.24391\n",
      "[270]\ttrain-mlogloss:1.12789\teval-mlogloss:1.24389\n",
      "[271]\ttrain-mlogloss:1.12749\teval-mlogloss:1.24391\n",
      "[272]\ttrain-mlogloss:1.12713\teval-mlogloss:1.24388\n",
      "[273]\ttrain-mlogloss:1.12669\teval-mlogloss:1.24385\n",
      "[274]\ttrain-mlogloss:1.12636\teval-mlogloss:1.24387\n",
      "[275]\ttrain-mlogloss:1.12604\teval-mlogloss:1.24387\n",
      "[276]\ttrain-mlogloss:1.12566\teval-mlogloss:1.24387\n",
      "[277]\ttrain-mlogloss:1.12523\teval-mlogloss:1.24386\n",
      "[278]\ttrain-mlogloss:1.12477\teval-mlogloss:1.24378\n",
      "[279]\ttrain-mlogloss:1.12441\teval-mlogloss:1.24376\n",
      "[280]\ttrain-mlogloss:1.12407\teval-mlogloss:1.24372\n",
      "[281]\ttrain-mlogloss:1.12374\teval-mlogloss:1.24371\n",
      "[282]\ttrain-mlogloss:1.12342\teval-mlogloss:1.2437\n",
      "[283]\ttrain-mlogloss:1.12302\teval-mlogloss:1.24369\n",
      "[284]\ttrain-mlogloss:1.12266\teval-mlogloss:1.24365\n",
      "[285]\ttrain-mlogloss:1.12227\teval-mlogloss:1.24362\n",
      "[286]\ttrain-mlogloss:1.12198\teval-mlogloss:1.24365\n",
      "[287]\ttrain-mlogloss:1.1216\teval-mlogloss:1.24362\n",
      "[288]\ttrain-mlogloss:1.12116\teval-mlogloss:1.24361\n",
      "[289]\ttrain-mlogloss:1.12076\teval-mlogloss:1.2436\n",
      "[290]\ttrain-mlogloss:1.12033\teval-mlogloss:1.2436\n",
      "[291]\ttrain-mlogloss:1.12008\teval-mlogloss:1.24362\n",
      "[292]\ttrain-mlogloss:1.1196\teval-mlogloss:1.24357\n",
      "[293]\ttrain-mlogloss:1.11917\teval-mlogloss:1.24353\n",
      "[294]\ttrain-mlogloss:1.11878\teval-mlogloss:1.2435\n",
      "[295]\ttrain-mlogloss:1.11846\teval-mlogloss:1.2435\n",
      "[296]\ttrain-mlogloss:1.11803\teval-mlogloss:1.24349\n",
      "[297]\ttrain-mlogloss:1.11759\teval-mlogloss:1.24347\n",
      "[298]\ttrain-mlogloss:1.11718\teval-mlogloss:1.24346\n",
      "[299]\ttrain-mlogloss:1.11673\teval-mlogloss:1.24345\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-c5bbc5a90a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwatch_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdvld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwatch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next_multi.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"next_multi.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ntree_limit = model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = XY.as_matrix(columns=features)\n",
    "Y = XY.as_matrix(columns=['y'])\n",
    "dX = xgb.DMatrix(X, label=Y, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evallist = [(dX, 'trnvld')]\n",
    "model = xgb.train(param, dX, best_ntree_limit, evals=evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:\n",
      "('renta', 42982)\n",
      "('antiguedad', 27830)\n",
      "('antiguedad_prev', 26261)\n",
      "('age', 26238)\n",
      "('age_prev', 23474)\n",
      "('fecha_alta_month', 21929)\n",
      "('nomprov', 16409)\n",
      "('fecha_alta_year', 16186)\n",
      "('canal_entrada', 13349)\n",
      "('renta_prev', 12254)\n",
      "('nomprov_prev', 11154)\n",
      "('canal_entrada_prev', 8944)\n",
      "('fecha_alta_month_prev', 6534)\n",
      "('ind_recibo_ult1_prev', 5745)\n",
      "('fecha_alta_year_prev', 5337)\n",
      "('ind_cco_fin_ult1_prev', 5301)\n",
      "('ind_ecue_fin_ult1_prev', 5237)\n",
      "('sexo', 5098)\n",
      "('ind_cno_fin_ult1_prev', 4526)\n",
      "('segmento', 3888)\n",
      "('ind_tjcr_fin_ult1_prev', 3806)\n",
      "('segmento_prev', 3577)\n",
      "('ind_reca_fin_ult1_prev', 3521)\n",
      "('ind_dela_fin_ult1_prev', 2821)\n",
      "('ind_ctop_fin_ult1_prev', 2762)\n",
      "('ind_nom_pens_ult1_prev', 2740)\n",
      "('ind_valo_fin_ult1_prev', 2291)\n",
      "('ind_nomina_ult1_prev', 2290)\n",
      "('ind_ctpp_fin_ult1_prev', 2171)\n",
      "('sexo_prev', 1874)\n",
      "('ind_fond_fin_ult1_prev', 1773)\n",
      "('tiprel_1mes_prev', 1665)\n",
      "('ind_ctma_fin_ult1_prev', 1560)\n",
      "('ind_actividad_cliente', 1537)\n",
      "('ind_actividad_cliente_prev', 1426)\n",
      "('tiprel_1mes', 1262)\n",
      "('ind_plan_fin_ult1_prev', 1259)\n",
      "('ind_deco_fin_ult1_prev', 1021)\n",
      "('indext', 944)\n",
      "('ind_nuevo', 772)\n",
      "('indext_prev', 742)\n",
      "('ind_hip_fin_ult1_prev', 734)\n",
      "('ind_nuevo_prev', 577)\n",
      "('pais_residencia', 518)\n",
      "('ind_empleado', 436)\n",
      "('ind_viv_fin_ult1_prev', 430)\n",
      "('pais_residencia_prev', 386)\n",
      "('ind_deme_fin_ult1_prev', 354)\n",
      "('ind_pres_fin_ult1_prev', 285)\n",
      "('ind_cder_fin_ult1_prev', 236)\n",
      "('indrel_1mes_prev', 193)\n",
      "('ult_fec_cli_1t_month', 165)\n",
      "('ind_ctju_fin_ult1_prev', 164)\n",
      "('indfall', 128)\n",
      "('ind_empleado_prev', 99)\n",
      "('indrel', 90)\n",
      "('indrel_prev', 71)\n",
      "('conyuemp_prev', 59)\n",
      "('ult_fec_cli_1t_month_prev', 56)\n",
      "('indfall_prev', 51)\n",
      "('indresi', 44)\n",
      "('ind_ahor_fin_ult1_prev', 37)\n",
      "('conyuemp', 25)\n",
      "('ult_fec_cli_1t_year', 19)\n",
      "('indresi_prev', 18)\n",
      "('ult_fec_cli_1t_year_prev', 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tst.as_matrix(columns=features)\n",
    "dtest = xgb.DMatrix(X_test, feature_names=features)\n",
    "\n",
    "preds = model.predict(dtest, ntree_limit=best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.27775329e-05,   1.41081036e-05,   2.14116899e-05, ...,\n",
       "          2.59958953e-02,   2.59767491e-02,   6.32383347e-01],\n",
       "       [  1.25464521e-05,   9.96616836e-06,   1.60573982e-05, ...,\n",
       "          2.34538540e-02,   2.25624815e-02,   6.63069665e-01],\n",
       "       [  4.12882036e-05,   5.50963960e-05,   4.90546256e-01, ...,\n",
       "          2.81150278e-04,   1.37237948e-04,   1.29365391e-04],\n",
       "       ..., \n",
       "       [  2.20387628e-05,   2.15961154e-05,   2.10560047e-05, ...,\n",
       "          8.32424685e-02,   8.35903063e-02,   6.25931501e-01],\n",
       "       [  8.43750422e-06,   9.31614068e-06,   1.13008400e-05, ...,\n",
       "          3.06048952e-02,   3.04748137e-02,   8.56111705e-01],\n",
       "       [  1.42435383e-05,   1.57267841e-05,   5.44787884e-01, ...,\n",
       "          5.21923564e-02,   1.38039082e-01,   6.74095601e-02]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subtract prev1 because possessed item cannot be bought\n",
    "preds = preds - tst.as_matrix(columns=[prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696539, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncodpers_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Booster.__del__ of <xgboost.core.Booster object at 0x7faa0e88a550>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/irteam/.pyenv/versions/3.6.4/envs/venv/lib/python3.6/site-packages/xgboost/core.py\", line 745, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'Booster' object has no attribute 'handle'\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for ncodper, pred in zip(ncodpers_tst, preds):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result.append([ip for y,p,ip in y_prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036981821651664248"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(add_tst_list, result, 7, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = submit.as_matrix(columns=features)\n",
    "dsubmit = xgb.DMatrix(X_submit, feature_names=features)\n",
    "\n",
    "preds_submit = model.predict(dsubmit, ntree_limit=best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract prev1 because possessed item cannot be bought\n",
    "preds_submit = preds_submit - submit.as_matrix(columns=[prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([660261])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncodpers_submit[929561]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write submission file\n",
    "submit_file = open('output/baseline.xgb', 'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_submit, preds_submit):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- private leaderboard 0.025018\n",
    "- rank : 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
