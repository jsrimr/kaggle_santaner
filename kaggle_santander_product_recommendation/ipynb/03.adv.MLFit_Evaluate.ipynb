{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Fit\n",
    "- train / dev / test split\n",
    "- ml fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cache\n",
    "trn = pd.read_csv('data/adv.feature_engineer.trn.csv')\n",
    "trg = pd.read_csv('data/adv.feature_engineer.y.csv')\n",
    "\n",
    "print('=' * 50)\n",
    "print('# Cross validation..')\n",
    "\n",
    "# XGB Model Param\n",
    "num_round = 500\n",
    "early_stop = 50\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'gamma': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 3,\n",
    "    'nthread': 4,\n",
    "    'num_class': 15,\n",
    "    'objective': 'multi:softprob',\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'seed': 777,\n",
    "    }\n",
    "\n",
    "trn_scores = []\n",
    "vld_scores = []\n",
    "best_iters = []\n",
    "n_splits = 2\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.05, random_state=777)\n",
    "for i, (t_ind, v_ind) in enumerate(sss.split(trn, trg)):\n",
    "    print('# Iter {} / {}'.format(i+1, n_splits))\n",
    "    x_trn = np.asarray(trn)[t_ind]\n",
    "    x_vld = np.asarray(trn)[v_ind]\n",
    "    y_trn = np.asarray(trg)[t_ind]\n",
    "    y_vld = np.asarray(trg)[v_ind]\n",
    "\n",
    "    dtrn = xgb.DMatrix(x_trn, label=y_trn)\n",
    "    dvld = xgb.DMatrix(x_vld, label=y_vld)\n",
    "    watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "\n",
    "    # fit xgb\n",
    "    bst = xgb.train(xgb_params, dtrn, num_round, watch_list,\n",
    "                    early_stopping_rounds=early_stop, verbose_eval=True)\n",
    "\n",
    "    # eval _ trn\n",
    "    score = log_loss(y_trn, bst.predict(dtrn))\n",
    "    trn_scores.append(score)\n",
    "\n",
    "    # eval _ vld\n",
    "    score = log_loss(y_vld, bst.predict(dvld))\n",
    "    vld_scores.append(score)\n",
    "\n",
    "    # best iters\n",
    "    best_iters.append(bst.best_iteration)\n",
    "\n",
    "print('# TRN logloss: {}'.format(np.mean(trn_scores)))\n",
    "print('# VLD logloss: {}'.format(np.mean(vld_scores)))\n",
    "print('# Best Iters : {}'.format(np.mean(best_iters)))\n",
    "\n",
    "##################################################################################################################\n",
    "# Model Fit\n",
    "##################################################################################################################\n",
    "\n",
    "print('=' * 50)\n",
    "print('# Refit and predict on test data..')\n",
    "dtrn = xgb.DMatrix(trn, label=trg)\n",
    "num_round = int(np.mean(best_iters) / 0.9)\n",
    "bst = xgb.train(xgb_params, dtrn, num_round, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('model/adv.trn-0.85.dev-1.83.xgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
