{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=7, default=0.0):\n",
    "    # MAP@7 이므로, 최대 7개만 사용한다\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # 점수를 부여하는 조건은 다음과 같다 :\n",
    "        # 예측값이 정답에 있고 (‘p in actual’)\n",
    "        # 예측값이 중복이 아니면 (‘p not in predicted[:i]’) \n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    # 정답값이 공백일 경우, 무조건 1.0점을 반환한다\n",
    "    if not actual:\n",
    "        return default\n",
    "\n",
    "    # 정답의 개수(len(actual))로 average precision을 구한다\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=7, default=0.0):\n",
    "    # list of list인 정답값(actual)과 예측값(predicted)에서 고객별 Average Precision을 구하고, np.mean()을 통해 평균을 계산한다\n",
    "    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.read_csv('data/train_ver2.csv')\n",
    "tst = pd.read_csv('data/test_ver2.csv')\n",
    "\n",
    "prods = trn.columns[24:].tolist()\n",
    "\n",
    "# fillna for target values\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
    "\n",
    "# remove no posessions\n",
    "no_product = trn[prods].sum(axis=1) == 0\n",
    "trn = trn[~no_product]\n",
    "\n",
    "# merge train and test\n",
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "df = pd.concat([trn, tst], axis=0)\n",
    "\n",
    "# features to use in learning\n",
    "features = []\n",
    "\n",
    "# preprocessing\n",
    "# categorical\n",
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', \n",
    "                'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel=-99)\n",
    "features += categorical_cols\n",
    "\n",
    "# numerical \n",
    "df['age'].replace(' NA', -99, inplace=True)\n",
    "df['age'] = df['age'].astype(np.int8)\n",
    "\n",
    "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
    "\n",
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'] = df['renta'].astype(float).astype(np.int8)\n",
    "\n",
    "df['indrel_1mes'].replace('P', 5, inplace=True)\n",
    "df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
    "\n",
    "features += ['age','antiguedad','renta','ind_nuevo','indrel','indrel_1mes','ind_actividad_cliente']\n",
    "\n",
    "## feature engineering - date variables\n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']\n",
    "\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']\n",
    "\n",
    "df.fillna(-99, inplace=True)\n",
    "\n",
    "## feature engineering - lag data\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] # \"2016-05-28\"\n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\n",
    "df_lag['int_date'] += 1\n",
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "del df, df_lag\n",
    "\n",
    "# fillna for first lag products NaN into 0\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace=True)\n",
    "    \n",
    "df_trn.fillna(-99, inplace=True)\n",
    "features += [feature + '_prev' for feature in features]\n",
    "features += [prod + '_prev' for prod in prods]\n",
    "\n",
    "###\n",
    "### more feature engineering here later\n",
    "###\n",
    "\n",
    "# prepare for model training\n",
    "trn = df_trn[~df_trn['fecha_dato'].isin(['2016-05-28', '2016-06-28'])]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-05-28']\n",
    "submit = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
    "\n",
    "del df_trn\n",
    "\n",
    "# get purchase only\n",
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y\n",
    "\n",
    "# train - valid split\n",
    "mask = np.random.rand(len(XY)) < 0.8\n",
    "XY_trn = XY[mask]\n",
    "XY_vld = XY[~mask]\n",
    "\n",
    "# preparing for evaluation/submission\n",
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "ncodpers_submit = submit.as_matrix(columns=['ncodpers'])\n",
    "\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    tst[padd] = tst[prod] - tst[prev]\n",
    "    \n",
    "add_tst = tst.as_matrix(columns=[prod + '_add' for prod in prods])\n",
    "add_tst_list = [list() for i in range(len(ncodpers_tst))]\n",
    "count_tst = 0\n",
    "for ncodper in range(len(ncodpers_tst)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_tst[ncodper, prod] > 0:\n",
    "            add_tst_list[ncodper].append(prod)\n",
    "            count_tst += 1\n",
    "\n",
    "# best score possible in test set (0.042663)\n",
    "print(mapk(add_tst_list, add_tst_list, 7, 0.0))\n",
    "\n",
    "\n",
    "# model training\n",
    "import xgboost as xgb\n",
    "\n",
    "param = {\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 8,\n",
    "    'nthread': 24,\n",
    "    'num_class': len(prods),\n",
    "    'objective': 'multi:softprob',\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'eta': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'colsample_bylevel': 0.9,\n",
    "    'seed': 2018,\n",
    "    }\n",
    "\n",
    "X_trn = XY_trn.as_matrix(columns=features)\n",
    "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
    "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
    "\n",
    "X_vld = XY_vld.as_matrix(columns=features)\n",
    "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "\n",
    "# TRAIN! - hold out validation\n",
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)\n",
    "\n",
    "import pickle\n",
    "pickle.dump(model, open(\"model/baseline.trn-vld.pkl\", \"wb\"))\n",
    "best_ntree_limit = model.best_ntree_limit\n",
    "\n",
    "# train full model for submission\n",
    "X = XY.as_matrix(columns=features)\n",
    "Y = XY.as_matrix(columns=['y'])\n",
    "dX = xgb.DMatrix(X, label=Y, feature_names=features)\n",
    "\n",
    "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n",
    "evallist = [(dX, 'trnvld')]\n",
    "# TRAIN with all data (train + valid)\n",
    "model = xgb.train(param, dX, best_ntree_limit, evals=evallist)\n",
    "\n",
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)\n",
    "    \n",
    "# evaluation on test set\n",
    "X_test = tst.as_matrix(columns=features)\n",
    "dtest = xgb.DMatrix(X_test, feature_names=features)\n",
    "preds = model.predict(dtest, ntree_limit=best_ntree_limit)\n",
    "\n",
    "# subtract prev1 because possessed item cannot be bought\n",
    "preds = preds - tst.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "\n",
    "result = []\n",
    "for ncodper, pred in zip(ncodpers_tst, preds):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result.append([ip for y,p,ip in y_prods])\n",
    "    \n",
    "# actual score in test set (0.042663)\n",
    "print(mapk(add_tst_list, result, 7, 0.0))\n",
    "\n",
    "\n",
    "# Submission\n",
    "X_submit = submit.as_matrix(columns=features)\n",
    "dsubmit = xgb.DMatrix(X_submit, feature_names=features)\n",
    "preds_submit = model.predict(dsubmit, ntree_limit=best_ntree_limit)\n",
    "\n",
    "# subtract prev1 because possessed item cannot be bought\n",
    "preds_submit = preds_submit - submit.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "\n",
    "# write submission file\n",
    "submit_file = open('output/baseline.xgb', 'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_submit, preds_submit):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.7633\teval-mlogloss:2.76435\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:2.56815\teval-mlogloss:2.56944\n",
      "[2]\ttrain-mlogloss:2.42815\teval-mlogloss:2.42978\n",
      "[3]\ttrain-mlogloss:2.31961\teval-mlogloss:2.32158\n",
      "[4]\ttrain-mlogloss:2.22782\teval-mlogloss:2.23006\n",
      "[5]\ttrain-mlogloss:2.15092\teval-mlogloss:2.15344\n",
      "[6]\ttrain-mlogloss:2.08519\teval-mlogloss:2.08796\n",
      "[7]\ttrain-mlogloss:2.02871\teval-mlogloss:2.03168\n",
      "[8]\ttrain-mlogloss:1.97987\teval-mlogloss:1.98308\n",
      "[9]\ttrain-mlogloss:1.93581\teval-mlogloss:1.93921\n",
      "[10]\ttrain-mlogloss:1.89617\teval-mlogloss:1.89976\n",
      "[11]\ttrain-mlogloss:1.86105\teval-mlogloss:1.86484\n",
      "[12]\ttrain-mlogloss:1.82875\teval-mlogloss:1.83278\n",
      "[13]\ttrain-mlogloss:1.80003\teval-mlogloss:1.80428\n",
      "[14]\ttrain-mlogloss:1.7743\teval-mlogloss:1.77871\n",
      "[15]\ttrain-mlogloss:1.75042\teval-mlogloss:1.75503\n",
      "[16]\ttrain-mlogloss:1.72864\teval-mlogloss:1.73345\n",
      "[17]\ttrain-mlogloss:1.70888\teval-mlogloss:1.7139\n",
      "[18]\ttrain-mlogloss:1.69054\teval-mlogloss:1.69576\n",
      "[19]\ttrain-mlogloss:1.67426\teval-mlogloss:1.67964\n",
      "[20]\ttrain-mlogloss:1.65869\teval-mlogloss:1.66426\n",
      "[21]\ttrain-mlogloss:1.64481\teval-mlogloss:1.65055\n",
      "[22]\ttrain-mlogloss:1.63219\teval-mlogloss:1.63808\n",
      "[23]\ttrain-mlogloss:1.62014\teval-mlogloss:1.62623\n",
      "[24]\ttrain-mlogloss:1.60912\teval-mlogloss:1.61537\n",
      "[25]\ttrain-mlogloss:1.59889\teval-mlogloss:1.60533\n",
      "[26]\ttrain-mlogloss:1.58933\teval-mlogloss:1.59596\n",
      "[27]\ttrain-mlogloss:1.58042\teval-mlogloss:1.58722\n",
      "[28]\ttrain-mlogloss:1.57229\teval-mlogloss:1.57926\n",
      "[29]\ttrain-mlogloss:1.56471\teval-mlogloss:1.57185\n",
      "[30]\ttrain-mlogloss:1.5578\teval-mlogloss:1.56512\n",
      "[31]\ttrain-mlogloss:1.55111\teval-mlogloss:1.5586\n",
      "[32]\ttrain-mlogloss:1.54494\teval-mlogloss:1.5526\n",
      "[33]\ttrain-mlogloss:1.53937\teval-mlogloss:1.5472\n",
      "[34]\ttrain-mlogloss:1.53416\teval-mlogloss:1.5422\n",
      "[35]\ttrain-mlogloss:1.52918\teval-mlogloss:1.53737\n",
      "[36]\ttrain-mlogloss:1.52443\teval-mlogloss:1.53277\n",
      "[37]\ttrain-mlogloss:1.52022\teval-mlogloss:1.52873\n",
      "[38]\ttrain-mlogloss:1.51607\teval-mlogloss:1.52475\n",
      "[39]\ttrain-mlogloss:1.51218\teval-mlogloss:1.52104\n",
      "[40]\ttrain-mlogloss:1.5085\teval-mlogloss:1.51754\n",
      "[41]\ttrain-mlogloss:1.50507\teval-mlogloss:1.51431\n",
      "[42]\ttrain-mlogloss:1.50189\teval-mlogloss:1.51128\n",
      "[43]\ttrain-mlogloss:1.49893\teval-mlogloss:1.50849\n",
      "[44]\ttrain-mlogloss:1.49596\teval-mlogloss:1.5057\n",
      "[45]\ttrain-mlogloss:1.49335\teval-mlogloss:1.50325\n",
      "[46]\ttrain-mlogloss:1.49083\teval-mlogloss:1.50091\n",
      "[47]\ttrain-mlogloss:1.48834\teval-mlogloss:1.49861\n",
      "[48]\ttrain-mlogloss:1.48599\teval-mlogloss:1.49643\n",
      "[49]\ttrain-mlogloss:1.48377\teval-mlogloss:1.49438\n",
      "[50]\ttrain-mlogloss:1.4817\teval-mlogloss:1.49249\n",
      "[51]\ttrain-mlogloss:1.47976\teval-mlogloss:1.49073\n",
      "[52]\ttrain-mlogloss:1.47788\teval-mlogloss:1.48902\n",
      "[53]\ttrain-mlogloss:1.4761\teval-mlogloss:1.48739\n",
      "[54]\ttrain-mlogloss:1.4744\teval-mlogloss:1.48587\n",
      "[55]\ttrain-mlogloss:1.4728\teval-mlogloss:1.48445\n",
      "[56]\ttrain-mlogloss:1.47129\teval-mlogloss:1.4831\n",
      "[57]\ttrain-mlogloss:1.46983\teval-mlogloss:1.4818\n",
      "[58]\ttrain-mlogloss:1.46843\teval-mlogloss:1.48057\n",
      "[59]\ttrain-mlogloss:1.46713\teval-mlogloss:1.47942\n",
      "[60]\ttrain-mlogloss:1.46589\teval-mlogloss:1.47835\n",
      "[61]\ttrain-mlogloss:1.46472\teval-mlogloss:1.47734\n",
      "[62]\ttrain-mlogloss:1.46357\teval-mlogloss:1.47637\n",
      "[63]\ttrain-mlogloss:1.46245\teval-mlogloss:1.47541\n",
      "[64]\ttrain-mlogloss:1.46138\teval-mlogloss:1.47449\n",
      "[65]\ttrain-mlogloss:1.46038\teval-mlogloss:1.47368\n",
      "[66]\ttrain-mlogloss:1.45941\teval-mlogloss:1.47289\n",
      "[67]\ttrain-mlogloss:1.45853\teval-mlogloss:1.47215\n",
      "[68]\ttrain-mlogloss:1.45762\teval-mlogloss:1.47139\n",
      "[69]\ttrain-mlogloss:1.45679\teval-mlogloss:1.47069\n",
      "[70]\ttrain-mlogloss:1.45592\teval-mlogloss:1.46999\n",
      "[71]\ttrain-mlogloss:1.45515\teval-mlogloss:1.46938\n",
      "[72]\ttrain-mlogloss:1.45441\teval-mlogloss:1.46879\n",
      "[73]\ttrain-mlogloss:1.4537\teval-mlogloss:1.46824\n",
      "[74]\ttrain-mlogloss:1.45301\teval-mlogloss:1.46768\n",
      "[75]\ttrain-mlogloss:1.45234\teval-mlogloss:1.46714\n",
      "[76]\ttrain-mlogloss:1.45165\teval-mlogloss:1.46662\n",
      "[77]\ttrain-mlogloss:1.45106\teval-mlogloss:1.46615\n",
      "[78]\ttrain-mlogloss:1.45044\teval-mlogloss:1.46566\n",
      "[79]\ttrain-mlogloss:1.4499\teval-mlogloss:1.46526\n",
      "[80]\ttrain-mlogloss:1.44934\teval-mlogloss:1.46487\n",
      "[81]\ttrain-mlogloss:1.44881\teval-mlogloss:1.46447\n",
      "[82]\ttrain-mlogloss:1.44826\teval-mlogloss:1.46408\n",
      "[83]\ttrain-mlogloss:1.44776\teval-mlogloss:1.46372\n",
      "[84]\ttrain-mlogloss:1.44728\teval-mlogloss:1.46337\n",
      "[85]\ttrain-mlogloss:1.44684\teval-mlogloss:1.46306\n",
      "[86]\ttrain-mlogloss:1.44637\teval-mlogloss:1.46273\n",
      "[87]\ttrain-mlogloss:1.44595\teval-mlogloss:1.46244\n",
      "[88]\ttrain-mlogloss:1.44548\teval-mlogloss:1.46214\n",
      "[89]\ttrain-mlogloss:1.44509\teval-mlogloss:1.46187\n",
      "[90]\ttrain-mlogloss:1.44466\teval-mlogloss:1.4616\n",
      "[91]\ttrain-mlogloss:1.44426\teval-mlogloss:1.46133\n",
      "[92]\ttrain-mlogloss:1.44386\teval-mlogloss:1.46108\n",
      "[93]\ttrain-mlogloss:1.44348\teval-mlogloss:1.46084\n",
      "[94]\ttrain-mlogloss:1.44306\teval-mlogloss:1.46057\n",
      "[95]\ttrain-mlogloss:1.4427\teval-mlogloss:1.46036\n",
      "[96]\ttrain-mlogloss:1.44234\teval-mlogloss:1.46014\n",
      "[97]\ttrain-mlogloss:1.442\teval-mlogloss:1.45991\n",
      "[98]\ttrain-mlogloss:1.44166\teval-mlogloss:1.45972\n",
      "[99]\ttrain-mlogloss:1.44131\teval-mlogloss:1.45951\n",
      "[100]\ttrain-mlogloss:1.44094\teval-mlogloss:1.4593\n",
      "[101]\ttrain-mlogloss:1.44063\teval-mlogloss:1.45912\n",
      "[102]\ttrain-mlogloss:1.44032\teval-mlogloss:1.45895\n",
      "[103]\ttrain-mlogloss:1.44005\teval-mlogloss:1.4588\n",
      "[104]\ttrain-mlogloss:1.43978\teval-mlogloss:1.45865\n",
      "[105]\ttrain-mlogloss:1.43952\teval-mlogloss:1.45852\n",
      "[106]\ttrain-mlogloss:1.43924\teval-mlogloss:1.45837\n",
      "[107]\ttrain-mlogloss:1.43897\teval-mlogloss:1.45823\n",
      "[108]\ttrain-mlogloss:1.43871\teval-mlogloss:1.45811\n",
      "[109]\ttrain-mlogloss:1.43841\teval-mlogloss:1.45797\n",
      "[110]\ttrain-mlogloss:1.43814\teval-mlogloss:1.45782\n",
      "[111]\ttrain-mlogloss:1.43789\teval-mlogloss:1.4577\n",
      "[112]\ttrain-mlogloss:1.43763\teval-mlogloss:1.45758\n",
      "[113]\ttrain-mlogloss:1.43741\teval-mlogloss:1.45746\n",
      "[114]\ttrain-mlogloss:1.43715\teval-mlogloss:1.45734\n",
      "[115]\ttrain-mlogloss:1.43689\teval-mlogloss:1.45722\n",
      "[116]\ttrain-mlogloss:1.43665\teval-mlogloss:1.45713\n",
      "[117]\ttrain-mlogloss:1.4364\teval-mlogloss:1.45703\n",
      "[118]\ttrain-mlogloss:1.43621\teval-mlogloss:1.45694\n",
      "[119]\ttrain-mlogloss:1.436\teval-mlogloss:1.45684\n",
      "[120]\ttrain-mlogloss:1.43575\teval-mlogloss:1.45674\n",
      "[121]\ttrain-mlogloss:1.43552\teval-mlogloss:1.45663\n",
      "[122]\ttrain-mlogloss:1.4353\teval-mlogloss:1.45653\n",
      "[123]\ttrain-mlogloss:1.4351\teval-mlogloss:1.45644\n",
      "[124]\ttrain-mlogloss:1.4349\teval-mlogloss:1.45635\n",
      "[125]\ttrain-mlogloss:1.4347\teval-mlogloss:1.45627\n",
      "[126]\ttrain-mlogloss:1.43452\teval-mlogloss:1.4562\n",
      "[127]\ttrain-mlogloss:1.43431\teval-mlogloss:1.45613\n",
      "[128]\ttrain-mlogloss:1.43408\teval-mlogloss:1.45603\n",
      "[129]\ttrain-mlogloss:1.43389\teval-mlogloss:1.45596\n",
      "[130]\ttrain-mlogloss:1.43368\teval-mlogloss:1.45588\n",
      "[131]\ttrain-mlogloss:1.43351\teval-mlogloss:1.45582\n",
      "[132]\ttrain-mlogloss:1.4333\teval-mlogloss:1.45574\n",
      "[133]\ttrain-mlogloss:1.4331\teval-mlogloss:1.45568\n",
      "[134]\ttrain-mlogloss:1.43288\teval-mlogloss:1.45559\n",
      "[135]\ttrain-mlogloss:1.43265\teval-mlogloss:1.4555\n",
      "[136]\ttrain-mlogloss:1.43244\teval-mlogloss:1.45543\n",
      "[137]\ttrain-mlogloss:1.43224\teval-mlogloss:1.45536\n",
      "[138]\ttrain-mlogloss:1.43205\teval-mlogloss:1.4553\n",
      "[139]\ttrain-mlogloss:1.43185\teval-mlogloss:1.45525\n",
      "[140]\ttrain-mlogloss:1.4317\teval-mlogloss:1.45521\n",
      "[141]\ttrain-mlogloss:1.4315\teval-mlogloss:1.45515\n",
      "[142]\ttrain-mlogloss:1.43124\teval-mlogloss:1.45506\n",
      "[143]\ttrain-mlogloss:1.43102\teval-mlogloss:1.45499\n",
      "[144]\ttrain-mlogloss:1.43084\teval-mlogloss:1.45495\n",
      "[145]\ttrain-mlogloss:1.43061\teval-mlogloss:1.45489\n",
      "[146]\ttrain-mlogloss:1.43046\teval-mlogloss:1.45485\n",
      "[147]\ttrain-mlogloss:1.43027\teval-mlogloss:1.4548\n",
      "[148]\ttrain-mlogloss:1.43008\teval-mlogloss:1.45475\n",
      "[149]\ttrain-mlogloss:1.42985\teval-mlogloss:1.45468\n",
      "[150]\ttrain-mlogloss:1.42965\teval-mlogloss:1.45463\n",
      "[151]\ttrain-mlogloss:1.42947\teval-mlogloss:1.4546\n",
      "[152]\ttrain-mlogloss:1.42928\teval-mlogloss:1.45454\n",
      "[153]\ttrain-mlogloss:1.42908\teval-mlogloss:1.4545\n",
      "[154]\ttrain-mlogloss:1.42889\teval-mlogloss:1.45448\n",
      "[155]\ttrain-mlogloss:1.4287\teval-mlogloss:1.45443\n",
      "[156]\ttrain-mlogloss:1.42854\teval-mlogloss:1.4544\n",
      "[157]\ttrain-mlogloss:1.42832\teval-mlogloss:1.45436\n",
      "[158]\ttrain-mlogloss:1.42812\teval-mlogloss:1.4543\n",
      "[159]\ttrain-mlogloss:1.42791\teval-mlogloss:1.45425\n",
      "[160]\ttrain-mlogloss:1.42771\teval-mlogloss:1.4542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttrain-mlogloss:1.42749\teval-mlogloss:1.45415\n",
      "[162]\ttrain-mlogloss:1.42727\teval-mlogloss:1.45409\n",
      "[163]\ttrain-mlogloss:1.42711\teval-mlogloss:1.45407\n",
      "[164]\ttrain-mlogloss:1.42689\teval-mlogloss:1.45404\n",
      "[165]\ttrain-mlogloss:1.42663\teval-mlogloss:1.45398\n",
      "[166]\ttrain-mlogloss:1.42641\teval-mlogloss:1.45392\n",
      "[167]\ttrain-mlogloss:1.42623\teval-mlogloss:1.45389\n",
      "[168]\ttrain-mlogloss:1.42601\teval-mlogloss:1.45382\n",
      "[169]\ttrain-mlogloss:1.42577\teval-mlogloss:1.45376\n",
      "[170]\ttrain-mlogloss:1.42554\teval-mlogloss:1.45371\n",
      "[171]\ttrain-mlogloss:1.42538\teval-mlogloss:1.45367\n",
      "[172]\ttrain-mlogloss:1.42519\teval-mlogloss:1.45364\n",
      "[173]\ttrain-mlogloss:1.42501\teval-mlogloss:1.45362\n",
      "[174]\ttrain-mlogloss:1.42477\teval-mlogloss:1.45357\n",
      "[175]\ttrain-mlogloss:1.4246\teval-mlogloss:1.45355\n",
      "[176]\ttrain-mlogloss:1.42443\teval-mlogloss:1.45351\n",
      "[177]\ttrain-mlogloss:1.42424\teval-mlogloss:1.45348\n",
      "[178]\ttrain-mlogloss:1.42404\teval-mlogloss:1.45346\n",
      "[179]\ttrain-mlogloss:1.42383\teval-mlogloss:1.45341\n",
      "[180]\ttrain-mlogloss:1.42363\teval-mlogloss:1.45337\n",
      "[181]\ttrain-mlogloss:1.4234\teval-mlogloss:1.45332\n",
      "[182]\ttrain-mlogloss:1.42318\teval-mlogloss:1.45328\n",
      "[183]\ttrain-mlogloss:1.42302\teval-mlogloss:1.45324\n",
      "[184]\ttrain-mlogloss:1.4228\teval-mlogloss:1.4532\n",
      "[185]\ttrain-mlogloss:1.42264\teval-mlogloss:1.45319\n",
      "[186]\ttrain-mlogloss:1.42247\teval-mlogloss:1.45316\n",
      "[187]\ttrain-mlogloss:1.42223\teval-mlogloss:1.45313\n",
      "[188]\ttrain-mlogloss:1.42203\teval-mlogloss:1.45309\n",
      "[189]\ttrain-mlogloss:1.42183\teval-mlogloss:1.45304\n",
      "[190]\ttrain-mlogloss:1.42166\teval-mlogloss:1.45303\n",
      "[191]\ttrain-mlogloss:1.42149\teval-mlogloss:1.45301\n",
      "[192]\ttrain-mlogloss:1.42129\teval-mlogloss:1.45299\n",
      "[193]\ttrain-mlogloss:1.42113\teval-mlogloss:1.45297\n",
      "[194]\ttrain-mlogloss:1.42095\teval-mlogloss:1.45295\n",
      "[195]\ttrain-mlogloss:1.42077\teval-mlogloss:1.45292\n",
      "[196]\ttrain-mlogloss:1.42058\teval-mlogloss:1.45291\n",
      "[197]\ttrain-mlogloss:1.42041\teval-mlogloss:1.4529\n",
      "[198]\ttrain-mlogloss:1.42022\teval-mlogloss:1.45287\n",
      "[199]\ttrain-mlogloss:1.42003\teval-mlogloss:1.45285\n",
      "[200]\ttrain-mlogloss:1.41984\teval-mlogloss:1.45282\n",
      "[201]\ttrain-mlogloss:1.41963\teval-mlogloss:1.45279\n",
      "[202]\ttrain-mlogloss:1.41942\teval-mlogloss:1.45276\n",
      "[203]\ttrain-mlogloss:1.41925\teval-mlogloss:1.45273\n",
      "[204]\ttrain-mlogloss:1.41909\teval-mlogloss:1.45272\n",
      "[205]\ttrain-mlogloss:1.41889\teval-mlogloss:1.4527\n",
      "[206]\ttrain-mlogloss:1.41875\teval-mlogloss:1.4527\n",
      "[207]\ttrain-mlogloss:1.41854\teval-mlogloss:1.45266\n",
      "[208]\ttrain-mlogloss:1.41832\teval-mlogloss:1.45262\n",
      "[209]\ttrain-mlogloss:1.41817\teval-mlogloss:1.45262\n",
      "[210]\ttrain-mlogloss:1.41803\teval-mlogloss:1.4526\n",
      "[211]\ttrain-mlogloss:1.41786\teval-mlogloss:1.45259\n",
      "[212]\ttrain-mlogloss:1.41768\teval-mlogloss:1.45258\n",
      "[213]\ttrain-mlogloss:1.41748\teval-mlogloss:1.45259\n",
      "[214]\ttrain-mlogloss:1.41728\teval-mlogloss:1.45257\n",
      "[215]\ttrain-mlogloss:1.41709\teval-mlogloss:1.45256\n",
      "[216]\ttrain-mlogloss:1.41695\teval-mlogloss:1.45257\n",
      "[217]\ttrain-mlogloss:1.41677\teval-mlogloss:1.45255\n",
      "[218]\ttrain-mlogloss:1.41656\teval-mlogloss:1.45252\n",
      "[219]\ttrain-mlogloss:1.41641\teval-mlogloss:1.45251\n",
      "[220]\ttrain-mlogloss:1.41622\teval-mlogloss:1.4525\n",
      "[221]\ttrain-mlogloss:1.41603\teval-mlogloss:1.45249\n",
      "[222]\ttrain-mlogloss:1.41586\teval-mlogloss:1.45248\n",
      "[223]\ttrain-mlogloss:1.41569\teval-mlogloss:1.45247\n",
      "[224]\ttrain-mlogloss:1.41553\teval-mlogloss:1.45245\n",
      "[225]\ttrain-mlogloss:1.41537\teval-mlogloss:1.45242\n",
      "[226]\ttrain-mlogloss:1.41516\teval-mlogloss:1.45239\n",
      "[227]\ttrain-mlogloss:1.41501\teval-mlogloss:1.45239\n",
      "[228]\ttrain-mlogloss:1.4148\teval-mlogloss:1.45236\n",
      "[229]\ttrain-mlogloss:1.41464\teval-mlogloss:1.45236\n",
      "[230]\ttrain-mlogloss:1.41444\teval-mlogloss:1.45232\n",
      "[231]\ttrain-mlogloss:1.41426\teval-mlogloss:1.45231\n",
      "[232]\ttrain-mlogloss:1.41409\teval-mlogloss:1.45229\n",
      "[233]\ttrain-mlogloss:1.41389\teval-mlogloss:1.45225\n",
      "[234]\ttrain-mlogloss:1.41368\teval-mlogloss:1.45221\n",
      "[235]\ttrain-mlogloss:1.41354\teval-mlogloss:1.45222\n",
      "[236]\ttrain-mlogloss:1.41334\teval-mlogloss:1.45217\n",
      "[237]\ttrain-mlogloss:1.41315\teval-mlogloss:1.45214\n",
      "[238]\ttrain-mlogloss:1.41297\teval-mlogloss:1.45213\n",
      "[239]\ttrain-mlogloss:1.41283\teval-mlogloss:1.45214\n",
      "[240]\ttrain-mlogloss:1.41268\teval-mlogloss:1.45212\n",
      "[241]\ttrain-mlogloss:1.41251\teval-mlogloss:1.45212\n",
      "[242]\ttrain-mlogloss:1.41232\teval-mlogloss:1.45209\n",
      "[243]\ttrain-mlogloss:1.41214\teval-mlogloss:1.45206\n",
      "[244]\ttrain-mlogloss:1.412\teval-mlogloss:1.45206\n",
      "[245]\ttrain-mlogloss:1.41181\teval-mlogloss:1.45204\n",
      "[246]\ttrain-mlogloss:1.41166\teval-mlogloss:1.45203\n",
      "[247]\ttrain-mlogloss:1.41151\teval-mlogloss:1.45203\n",
      "[248]\ttrain-mlogloss:1.41132\teval-mlogloss:1.45202\n",
      "[249]\ttrain-mlogloss:1.41116\teval-mlogloss:1.45203\n",
      "[250]\ttrain-mlogloss:1.41098\teval-mlogloss:1.45204\n",
      "[251]\ttrain-mlogloss:1.41082\teval-mlogloss:1.45203\n",
      "[252]\ttrain-mlogloss:1.41063\teval-mlogloss:1.45203\n",
      "[253]\ttrain-mlogloss:1.41046\teval-mlogloss:1.45202\n",
      "[254]\ttrain-mlogloss:1.4103\teval-mlogloss:1.45201\n",
      "[255]\ttrain-mlogloss:1.41007\teval-mlogloss:1.45198\n",
      "[256]\ttrain-mlogloss:1.40991\teval-mlogloss:1.45198\n",
      "[257]\ttrain-mlogloss:1.40977\teval-mlogloss:1.45197\n",
      "[258]\ttrain-mlogloss:1.40961\teval-mlogloss:1.45198\n",
      "[259]\ttrain-mlogloss:1.40943\teval-mlogloss:1.45196\n",
      "[260]\ttrain-mlogloss:1.40924\teval-mlogloss:1.45194\n",
      "[261]\ttrain-mlogloss:1.40905\teval-mlogloss:1.45192\n",
      "[262]\ttrain-mlogloss:1.40889\teval-mlogloss:1.45192\n",
      "[263]\ttrain-mlogloss:1.40874\teval-mlogloss:1.45191\n",
      "[264]\ttrain-mlogloss:1.40856\teval-mlogloss:1.4519\n",
      "[265]\ttrain-mlogloss:1.40841\teval-mlogloss:1.45191\n",
      "[266]\ttrain-mlogloss:1.40824\teval-mlogloss:1.45189\n",
      "[267]\ttrain-mlogloss:1.40807\teval-mlogloss:1.45188\n",
      "[268]\ttrain-mlogloss:1.40793\teval-mlogloss:1.45187\n",
      "[269]\ttrain-mlogloss:1.40778\teval-mlogloss:1.45185\n",
      "[270]\ttrain-mlogloss:1.40764\teval-mlogloss:1.45185\n",
      "[271]\ttrain-mlogloss:1.40747\teval-mlogloss:1.45185\n",
      "[272]\ttrain-mlogloss:1.4073\teval-mlogloss:1.45186\n",
      "[273]\ttrain-mlogloss:1.40712\teval-mlogloss:1.45185\n",
      "[274]\ttrain-mlogloss:1.407\teval-mlogloss:1.45185\n",
      "[275]\ttrain-mlogloss:1.40681\teval-mlogloss:1.45185\n",
      "[276]\ttrain-mlogloss:1.40666\teval-mlogloss:1.45184\n"
     ]
    }
   ],
   "source": [
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"next_multi.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ntree_limit = model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = XY.as_matrix(columns=features)\n",
    "Y = XY.as_matrix(columns=['y'])\n",
    "dX = xgb.DMatrix(X, label=Y, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evallist = [(dX, 'trnvld')]\n",
    "model = xgb.train(param, dX, best_ntree_limit, evals=evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tst.as_matrix(columns=features)\n",
    "dtest = xgb.DMatrix(X_test, feature_names=features)\n",
    "\n",
    "preds = model.predict(dtest, ntree_limit=best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subtract prev1 because possessed item cannot be bought\n",
    "preds = preds - tst.as_matrix(columns=[prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncodpers_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for ncodper, pred in zip(ncodpers_tst, preds):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result.append([ip for y,p,ip in y_prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapk(add_tst_list, result, 7, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = submit.as_matrix(columns=features)\n",
    "dsubmit = xgb.DMatrix(X_submit, feature_names=features)\n",
    "\n",
    "preds_submit = model.predict(dsubmit, ntree_limit=best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract prev1 because possessed item cannot be bought\n",
    "preds_submit = preds_submit - submit.as_matrix(columns=[prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncodpers_submit[929561]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write submission file\n",
    "submit_file = open('output/baseline.xgb', 'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_submit, preds_submit):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- private leaderboard 0.025018\n",
    "- rank : 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
