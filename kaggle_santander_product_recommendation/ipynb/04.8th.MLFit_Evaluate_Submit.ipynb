{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import engines\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import io\n",
    "np.random.seed(2016)\n",
    "\n",
    "def make_submission(f, Y_test, C):\n",
    "    Y_ret = []\n",
    "    with Timer(\"make submission\"):\n",
    "        f.write(\"ncodpers,added_products\\n\".encode('utf-8'))\n",
    "        for c, y_test in zip(C, Y_test):\n",
    "            y_prods = [(y,p,ip) for y,p,ip in zip(y_test, products, range(len(products)))]\n",
    "            y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "            Y_ret.append([ip for y,p,ip in y_prods])\n",
    "            y_prods = [p for y,p,ip in y_prods]\n",
    "            f.write((\"%s,%s\\n\" % (int(c), \" \".join(y_prods))).encode('utf-8'))\n",
    "    return Y_ret\n",
    "\n",
    "\n",
    "# uses designates tr_date as test and all data before as train\n",
    "def train_predict(all_df, features, prod_features, str_date, cv):\n",
    "    test_date = date_to_int(str_date)\n",
    "    train_df = all_df[all_df.int_date < test_date]\n",
    "    test_df = pd.DataFrame(all_df[all_df.int_date == test_date])\n",
    "    print(sorted(set(train_df.columns.values.tolist()))) # print colnames\n",
    "    print(len(train_df.columns.values.tolist()), len(set(train_df.columns.values.tolist()))) # check duplicate\n",
    "    print(len(features),len(set(features))) # check duplicate\n",
    "\n",
    "    ### LEARNT clever, smart method to get the purchase\n",
    "    # subset train data to purchases only\n",
    "    # get single multi-class target as well\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i, prod in enumerate(products):\n",
    "        prev = prod + \"_prev1\"\n",
    "        prX = train_df[(train_df[prod] == 1) & (train_df[prev] == 0)] # select those who purchased a product\n",
    "        prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "        X.append(prX)\n",
    "        Y.append(prY)\n",
    "        print(prod, prX.shape)\n",
    "\n",
    "\n",
    "    XY = pd.concat(X)\n",
    "    Y = np.hstack(Y)\n",
    "    XY[\"y\"] = Y\n",
    "    XY[\"url\"] = np.zeros(len(XY), dtype=np.int8) ### WHY is this url here for?\n",
    "    # XY is now train data with actual purchases and its target labels\n",
    "\n",
    "    del train_df\n",
    "    del all_df\n",
    "\n",
    "\n",
    "    XY[\"ncodepers_fecha_dato\"] = XY[\"ncodpers\"].astype(str) + XY[\"fecha_dato\"]\n",
    "    uniqs, counts = np.unique(XY[\"ncodepers_fecha_dato\"], return_counts=True)\n",
    "    weights = np.exp(1/counts - 1)\n",
    "    # LEARNT giving exponential less weight to same user data in each month, due to multiple purchases\n",
    "    print(np.unique(counts, return_counts=True))\n",
    "    print(np.unique(weights, return_counts=True))\n",
    "    wdf = pd.DataFrame()\n",
    "    wdf[\"ncodepers_fecha_dato\"] = uniqs\n",
    "    wdf[\"counts\"] = counts\n",
    "    wdf[\"weight\"] = weights\n",
    "    print(\"before merge\", len(XY))\n",
    "    # merge unique counts and its weights to main data\n",
    "    XY = XY.merge(wdf, on=\"ncodepers_fecha_dato\")\n",
    "    print(\"after merge\", len(XY))\n",
    "\n",
    "    print(XY.shape)\n",
    "\n",
    "    mask = np.random.rand(len(XY)) < 0.8 # 80 percent as train, 20 percent as valid\n",
    "    XY_train = XY[mask]\n",
    "    XY_validate = XY[~mask]\n",
    "\n",
    "    with Timer(\"prepare test data\"):\n",
    "        test_df[\"y\"] = test_df[\"ncodpers\"]\n",
    "        test_df[\"url\"] = np.zeros(len(test_df), dtype=np.int8)\n",
    "        test_df[\"weight\"] = np.ones(len(test_df), dtype=np.int8) # weight of one to test data\n",
    "        Y_prev = test_df.as_matrix(columns=prod_features) # lag-1 products\n",
    "        C = test_df.as_matrix(columns=[\"ncodpers\"])\n",
    "        for prod in products:\n",
    "            prev = prod + \"_prev1\"\n",
    "            padd = prod + \"_add\"\n",
    "            test_df[padd] = test_df[prod] - test_df[prev]\n",
    "            # cv = True,  test_df has this value, and calculates purchase\n",
    "            # cv = False, test_df does not have test_df[prod] WHY\n",
    "        test_add_mat = test_df.as_matrix(columns=[prod + \"_add\" for prod in products])\n",
    "        test_add_list = [list() for i in range(len(C))] # list of empty list with size equal to test_df row\n",
    "        assert test_add_mat.shape == (len(C), len(products))\n",
    "        count = 0\n",
    "        for c in range(len(C)):\n",
    "            for p in range(len(products)):\n",
    "                if test_add_mat[c,p] > 0:\n",
    "                    test_add_list[c].append(p)\n",
    "                    count += 1\n",
    "        # test_add_list is a list of purchased items per user in test_df\n",
    "        # this is only useful for cv purpose, not for actual predcition on real test_df\n",
    "\n",
    "    if cv:\n",
    "        max_map7 = mapk(test_add_list, test_add_list, 7, 0.0)\n",
    "        map7coef = float(len(test_add_list)) / float(sum([int(bool(a)) for a in test_add_list]))\n",
    "        print(\"Max MAP@7\", str_date, max_map7, max_map7*map7coef)\n",
    "\n",
    "    with Timer(\"XGBoost\"):\n",
    "        Y_test_xgb = engines.xgboost(XY_train, XY_validate, test_df, features, XY_all = XY,\n",
    "            restore = (str_date == \"2016-06-28\")\n",
    "        )\n",
    "        # LEARNT doing Y_test_xgb - Y_prev is removing predictions if bought in prev month!\n",
    "        test_add_list_xgboost = make_submission(io.BytesIO() if cv else gzip.open(\"output/8th.%s.xgb.csv.gz\" % str_date, \"wb\"),\n",
    "                                                Y_test_xgb - Y_prev, C)\n",
    "        if cv:\n",
    "            map7xgboost = mapk(test_add_list, test_add_list_xgboost, 7, 0.0)\n",
    "            print(\"XGBoost MAP@7\", str_date, map7xgboost, map7xgboost*map7coef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "all_df = pickle.load(open('data/8th.feature_engineer.all.pkl', 'rb'))\n",
    "features, prod_features = pickle.load(open('data/8th.feature_engineer.cv_meta.pkl', 'rb'))\n",
    "\n",
    "train_predict(all_df, features, prod_features, \"2016-05-28\", cv=True)\n",
    "train_predict(all_df, features, prod_features, \"2016-06-28\", cv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소요 시간 : ~3시간\n",
    "점수 : \n",
    "  - Public : 0.0305956\n",
    "  - Private : 0.0309524\n",
    "  - Rank : 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10, default=1.0):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return default\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10, default=1.0):\n",
    "    return np.mean([apk(a,p,k,default) for a,p in zip(actual, predicted)]) ### LEARNT good use of zip in loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
